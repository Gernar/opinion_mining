{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from parser import PackToDocks\n",
    "import codecs \n",
    "import os\n",
    "import glob\n",
    "from sklearn.cluster import KMeans\n",
    "import artm\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import re\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list_trump = PackToDocks('trump_labelled.txt', 'data_trump')\n",
    "class_list_DNR = PackToDocks('lnr_dnr_labelled.txt', 'data_DNR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClearTable(table):\n",
    "    for i in table:\n",
    "        if i[0]==i[1]:\n",
    "            table[i] == False\n",
    "        else:\n",
    "            table[i] == 0\n",
    "\n",
    "def Add(dic, value):\n",
    "    if value in dic:\n",
    "        dic[value] +=1\n",
    "    else:\n",
    "        dic[value] = 1\n",
    "\n",
    "def All(dic):\n",
    "    for i in dic:\n",
    "        if i[0] == i[1] and dic[i] == False:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def GetDict(cluster_list, class_list):\n",
    "    s = set()\n",
    "    d = {}\n",
    "    for x in cluster_list:\n",
    "        s.add(x)\n",
    "    for kek in s:\n",
    "        self_d = {}\n",
    "        for i in s:\n",
    "            self_d[i] = 0\n",
    "        for i in range(len(cluster_list)):\n",
    "            if cluster_list[i] == kek:\n",
    "                Add(self_d, class_list[i])\n",
    "        d[kek] = dict(self_d)\n",
    "    return d\n",
    "def Swap(cluster_list, class_list, max_key):\n",
    "    for i in range(len(cluster_list)):\n",
    "        if cluster_list[i] == max_key[0]:\n",
    "            cluster_list[i] = max_key[1]\n",
    "        elif cluster_list[i] == max_key[1]:\n",
    "            cluster_list[i] = max_key[0]\n",
    "def CPS(cluster_list, class_list):\n",
    "    s = set()\n",
    "    for x in cluster_list:\n",
    "        s.add(x)\n",
    "    table = {}\n",
    "    for i in combinations(list(s), 2):\n",
    "        table[i] = 0\n",
    "    for i in s:\n",
    "        table[(i, i)] = False\n",
    "    while True:\n",
    "        d = GetDict(cluster_list, class_list)\n",
    "        for line in table:\n",
    "            if line[0] != line[1]:\n",
    "                table[line] = d[line[0]][line[1]] + d[line[1]][line[0]]\n",
    "            else:\n",
    "                table[line] = d[line[0]][line[1]]\n",
    "        max_key = None\n",
    "        for line in table:\n",
    "            if table[line] > table[(line[0], line[0])] + table[(line[1], line[1])]:\n",
    "                if max_key == None:\n",
    "                    max_key = line\n",
    "                elif table[max_key] < table[line]:\n",
    "                    max_key = line\n",
    "        if max_key == None:\n",
    "            break\n",
    "        else:\n",
    "            Swap(cluster_list, class_list, max_key)\n",
    "\n",
    "    counter = 0\n",
    "    for i,x in enumerate(class_list):\n",
    "        if x == cluster_list[i]:\n",
    "            counter += 1\n",
    "    return counter/len(class_list)\n",
    "\n",
    "\n",
    "def PWS(class_list, cluster_list):\n",
    "    PW = 0\n",
    "    counter = 0\n",
    "    for i, x in enumerate(class_list):\n",
    "        for j, y in enumerate(class_list):\n",
    "            if x == y:\n",
    "                counter += 1\n",
    "                PW += int(cluster_list[i] == cluster_list[j])\n",
    "\n",
    "    return (PW/counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clustering(data_path, num_topics = 3, alpha = 0.1, beta = 0.1, \n",
    "               num_document_passes = 50, \n",
    "               num_collection_passes = 50,\n",
    "               num_tokens = 10,\n",
    "              dimension = 5,\n",
    "              n_clusters = 3):\n",
    "    file_list = [file for file in os.listdir(data_path) if os.path.isfile(data_path + '/' + file)]\n",
    "    file_list.sort(key = lambda x: int(x[2:-4]))\n",
    "    stopword_set = set(stopwords.words('russian') + [u'тот', u'этот', u'он', u'она', u'оно', u'наш', u'ваш', u'это', u'быть'])\n",
    "    \n",
    "    files = []\n",
    "    for j, file in enumerate(file_list):\n",
    "        with codecs.open(data_path + '/' + file, 'r', 'utf-8') as f:\n",
    "            sentences = re.split('(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', f.read())\n",
    "            with codecs.open('vw.sentences.txt', 'w', 'utf-8') as s:\n",
    "                for i, sentence in enumerate(sentences):\n",
    "                    sent_list = nltk.word_tokenize(sentence)\n",
    "                    sent_list = [sent.lower() for sent in sent_list if (sent.isalpha() and sent.lower() not in stopword_set)]\n",
    "                    string = u'{0} |@default_class {1}'.format(str(i), ' '.join(sent_list))\n",
    "                    s.write(string + '\\n')\n",
    "        batch_vectorizer = artm.BatchVectorizer(data_path = 'vw.sentences.txt', \n",
    "                                                data_format = 'vowpal_wabbit', \n",
    "                                                target_folder = 'TM/batches')\n",
    "        lda = artm.LDA(dictionary = batch_vectorizer.dictionary, \n",
    "                       num_topics = num_topics, \n",
    "                       alpha = alpha, \n",
    "                       beta = beta, \n",
    "                       num_document_passes = num_document_passes)\n",
    "        lda.fit_offline(batch_vectorizer = batch_vectorizer, num_collection_passes = num_collection_passes)\n",
    "        \n",
    "        top_tokens = lda.get_top_tokens(num_tokens = num_tokens)\n",
    "        \n",
    "        words = []\n",
    "        for topic in top_tokens:\n",
    "            words += topic\n",
    "        print file + ': ' + u' '.join(words)\n",
    "        tag = TaggedDocument(words,[j])\n",
    "        files.append(tag)\n",
    "        \n",
    "    vecs = np.zeros(shape = (len(file_list), dimension))\n",
    "    model = Doc2Vec(files, vector_size=dimension, window=2, min_count=1, workers=4, dm = 1)\n",
    "    for i in range(len(file_list)):\n",
    "        vecs[i] = model.docvecs[i]\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(vecs)\n",
    "    return kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_0.txt: действия народной стороны\n",
      "d_1.txt: ахметова андрей днр\n",
      "d_2.txt: действий рф курченко\n",
      "d_3.txt: боевики боевики днр\n",
      "d_4.txt: свидетелями которые людям\n",
      "d_5.txt: боевики связи связи\n",
      "d_6.txt: александра действий согласно\n",
      "d_7.txt: эскалации документов украины\n",
      "d_8.txt: днр ахметова долларов\n",
      "d_9.txt: предприятий сказал днр\n",
      "d_10.txt: участники блокады украины\n",
      "d_11.txt: предприятий боевиков захарченко\n",
      "d_12.txt: украины донбасса днр\n",
      "d_13.txt: днр государства заявил\n",
      "d_14.txt: идет думаю днр\n",
      "d_15.txt: дефицит крайне донбасса\n",
      "d_16.txt: соцсети закончилась торговую\n",
      "d_17.txt: поставки торговой лнр\n",
      "d_18.txt: отметил олигарха ахметов\n",
      "d_19.txt: украинского украины который\n",
      "d_20.txt: государство позабыли важна\n",
      "d_21.txt: марта кроме украину\n",
      "d_22.txt: блокады предприятий днр\n",
      "d_23.txt: тонн которые днр\n",
      "d_24.txt: блокады заводы блокада\n",
      "d_25.txt: лнр скм скм\n",
      "d_26.txt: также украины порошенко\n",
      "d_27.txt: песков которые заявил\n",
      "d_28.txt: национализацию наряду украины\n",
      "d_29.txt: украины перехват днр\n",
      "d_30.txt: рады будут блокада\n",
      "d_31.txt: чао ооо предприятий\n",
      "d_32.txt: отторгнуты песков государством\n",
      "d_33.txt: виногродский торговли штаба\n",
      "d_34.txt: потери уйдет осуществлять\n",
      "d_35.txt: будут министр украина\n",
      "d_36.txt: порошенко предприятия россией\n",
      "d_37.txt: лнр товаров радикалы\n",
      "d_38.txt: виногродский также штаб\n",
      "d_39.txt: республик ситуации украинской\n",
      "d_40.txt: днр говорит донбасса\n",
      "d_41.txt: украине интересы россией\n",
      "d_42.txt: порошенко днр цеголко\n",
      "d_43.txt: предоставлять министр днр\n",
      "d_44.txt: донецк песков донецк\n",
      "d_45.txt: сознательной украины днр\n",
      "d_46.txt: днр петренко подчеркнул\n",
      "d_47.txt: отжимом этих думаю\n",
      "d_48.txt: которые предприятия украинские\n",
      "d_49.txt: украине отметил которые\n",
      "d_50.txt: донбасса киев предприятиях\n",
      "d_51.txt: предприятий территории украинских\n",
      "d_52.txt: днр этим киев\n",
      "d_53.txt: предприятий scm собственность\n",
      "d_54.txt: казахстан захарченко днр\n",
      "d_55.txt: предприятий казахстан сегодня\n",
      "d_56.txt: порошенко предприятия россией\n",
      "d_57.txt: украины россия территории\n",
      "d_58.txt: рф лнр информационное\n",
      "d_59.txt: донбасса года украины\n",
      "d_60.txt: песков области оккупированных\n",
      "d_61.txt: трапезниковым боевики блокаду\n",
      "d_62.txt: завод украинских предприятий\n",
      "d_63.txt: порошенко состоялся украины\n",
      "d_64.txt: лнр вводится издание\n",
      "d_65.txt: днр которые блокаду\n",
      "d_66.txt: потери уйдет украине\n",
      "d_67.txt: потери уйдет украине\n",
      "d_68.txt: станции дфс днр\n",
      "d_69.txt: ордило украина никто\n",
      "d_70.txt: введении захарченко днр\n",
      "d_71.txt: днр предприятиях завод\n",
      "d_72.txt: предприятий днр днр\n",
      "d_73.txt: дейнего народной собственника\n",
      "d_74.txt: чао ооо дтэк\n",
      "d_75.txt: нарушение украины порошенко\n",
      "d_76.txt: семенченко территории договориться\n",
      "d_77.txt: предприятий предприятий решил\n",
      "d_78.txt: украинские оккупированных донбасса\n",
      "d_79.txt: захарченко лнр стоило\n",
      "d_80.txt: признание порошенко украины\n",
      "d_81.txt: порошенко украины международного\n",
      "d_82.txt: блокады донбасских предприятия\n",
      "d_83.txt: слухи донбассе киеву\n",
      "d_84.txt: россии заявил марта\n",
      "d_85.txt: днр этим киев\n",
      "d_86.txt: лнр коксохим днр\n",
      "d_87.txt: россии порошенко считает\n",
      "d_88.txt: предприятий луганской скм\n",
      "d_89.txt: порошенко предприятия россией\n",
      "d_90.txt: скм днр скм\n",
      "d_91.txt: украины шаги украины\n",
      "d_92.txt: фоне великобритании территории\n",
      "d_93.txt: пао ооо министерство\n",
      "d_94.txt: днр захарченко предприятиях\n",
      "d_95.txt: песков которые блокаду\n",
      "d_96.txt: предприятий боевиков захарченко\n",
      "d_97.txt: боевиков боевиков марта\n",
      "d_98.txt: предприятий уголь порошенко\n",
      "d_0.txt: выбросов соглашение сша\n",
      "d_1.txt: участники стала борьбе\n",
      "d_2.txt: участники стала борьбе\n",
      "d_3.txt: соглашение трамп саммита\n",
      "d_4.txt: соглашение трамп саммита\n",
      "d_5.txt: выбросов сша сша\n",
      "d_6.txt: сша дональд илон\n",
      "d_7.txt: выбросов сша соглашение\n",
      "d_8.txt: выбросов соглашения климату\n",
      "d_9.txt: соглашение соглашения выбросов\n",
      "d_10.txt: выбросов соглашение соглашения\n",
      "d_11.txt: парижского ходе климату\n",
      "d_12.txt: выбросов трамп соглашение\n",
      "d_13.txt: государства отметил соглашения\n",
      "d_14.txt: сша угроза климату\n",
      "d_15.txt: выбросов однако климату\n",
      "d_16.txt: соглашения трамп соглашение\n",
      "d_17.txt: парижского оон сша\n",
      "d_18.txt: поста сообщил маск\n",
      "d_19.txt: соглашения страны саммите\n",
      "d_20.txt: потепления сша соглашения\n",
      "d_21.txt: выбросов своем соглашение\n",
      "d_22.txt: климата трамп климату\n",
      "d_23.txt: соглашения сша которого\n",
      "d_24.txt: соглашение сша года\n",
      "d_25.txt: туск twitter туск\n",
      "d_26.txt: государства соглашение соглашения\n",
      "d_27.txt: ключевых трамп сша\n",
      "d_28.txt: соглашения соглашение соглашение\n",
      "d_29.txt: сша трамп соглашения\n",
      "d_30.txt: выход конвенции сша\n",
      "d_31.txt: соглашение сша соглашение\n",
      "d_32.txt: заявил соглашения соглашения\n",
      "d_33.txt: года сша климату\n",
      "d_34.txt: климату случае соглашения\n",
      "d_35.txt: выбросов сша парижское\n",
      "d_36.txt: выбросов сша парижское\n",
      "d_37.txt: соглашение сша сша\n",
      "d_38.txt: лидеров лидеров большой\n",
      "d_39.txt: решение сша соглашения\n",
      "d_40.txt: выход детали решение\n",
      "d_41.txt: государства отметил климату\n",
      "d_42.txt: климата климата европейские\n",
      "d_43.txt: сделал соглашение соглашения\n",
      "d_44.txt: соглашение сша соглашение\n",
      "d_45.txt: планету трампа соглашения\n",
      "d_46.txt: маск парижского соглашения\n",
      "d_47.txt: решение президент мая\n",
      "d_48.txt: климату соглашения соглашение\n",
      "d_49.txt: пределах сша соглашение\n",
      "d_50.txt: решение соглашения соглашение\n",
      "d_51.txt: своем сша соглашение\n",
      "d_52.txt: ранее трамп сша\n",
      "d_53.txt: сша глава трампа\n",
      "d_54.txt: года сша климату\n",
      "d_55.txt: пока прюитт соглашения\n",
      "d_56.txt: германии сша соглашение\n",
      "d_57.txt: трампа смогли климату\n",
      "d_58.txt: сша трамп соглашение\n",
      "d_59.txt: написал вопросам сша\n",
      "d_60.txt: парижского трамп газов\n",
      "d_61.txt: привержен говорится климату\n",
      "d_62.txt: соглашения соглашение года\n",
      "d_63.txt: соглашения соглашение года\n",
      "d_64.txt: потепления опек соглашения\n",
      "d_65.txt: вашингтона выполнять выполнять\n",
      "d_66.txt: трампа лидеры климату\n",
      "d_67.txt: решение сша климату\n",
      "d_68.txt: трамп окружающей соглашения\n",
      "d_69.txt: защите окружающей соглашения\n",
      "d_70.txt: прюитт парижского сша\n",
      "d_71.txt: пределах сша сша\n",
      "d_72.txt: сша сохранения президент\n",
      "d_73.txt: прюитт сша соглашения\n",
      "d_74.txt: сша соглашение сша\n",
      "d_75.txt: сша маск соглашения\n",
      "d_76.txt: климату парижское сша\n",
      "d_77.txt: соглашение сша сша\n",
      "d_78.txt: написал вопросам соглашения\n",
      "d_79.txt: сша будут сша\n",
      "d_80.txt: сша трамп климату\n",
      "d_81.txt: сша соглашение сша\n",
      "d_82.txt: написал сша маск\n",
      "d_83.txt: изменением климата парижского\n",
      "d_84.txt: изменением климата парижского\n",
      "d_85.txt: китай прюитт соглашения\n",
      "d_86.txt: сша трамп соглашение\n",
      "d_87.txt: сша трамп парниковых\n",
      "d_88.txt: трамп соглашение сша\n",
      "d_89.txt: риски соглашение сша\n",
      "d_90.txt: сша трамп париже\n",
      "d_91.txt: сша трамп париже\n",
      "d_92.txt: маск парижского соглашения\n",
      "d_93.txt: стоит климату маск\n",
      "d_94.txt: трамп решение маск\n",
      "d_95.txt: заявил сша соглашения\n",
      "d_96.txt: температуры соглашение сша\n",
      "d_97.txt: трамп сша сша\n",
      "d_98.txt: написал решение маск\n",
      "d_99.txt: заявил трамп соглашения\n",
      "d_100.txt: заявил решение соглашения\n",
      "d_101.txt: заявил решение соглашения\n",
      "d_102.txt: tesla пытался парижского\n",
      "d_103.txt: словам сша парижского\n",
      "d_104.txt: макрон хотим мир\n",
      "d_105.txt: соглашения борьбе парниковых\n",
      "d_106.txt: соглашения белом соглашения\n",
      "d_107.txt: сша оон оон\n",
      "d_108.txt: фонд долларов парижского\n",
      "d_109.txt: фонд долларов парижского\n",
      "d_110.txt: роста сша соглашения\n",
      "d_111.txt: словам сша парижского\n",
      "d_112.txt: заявил сша соглашения\n",
      "d_113.txt: планеты сша соглашения\n",
      "d_114.txt: дюжаррик дюжаррик словам\n",
      "d_115.txt: сша саду сша\n",
      "d_116.txt: нашей сша стран\n",
      "d_117.txt: сделает оон сша\n",
      "d_118.txt: правительств парижское парижского\n",
      "d_119.txt: президента прюитт парижского\n",
      "d_120.txt: президент сша соглашение\n",
      "d_121.txt: решение климату стран\n",
      "d_122.txt: соглашения сша климату\n",
      "d_123.txt: меркель время парижской\n",
      "d_124.txt: спиной парижское парижского\n",
      "d_125.txt: спиной парижское парижского\n",
      "d_126.txt: заявил решение соглашения\n",
      "d_127.txt: сша рабочих сша\n",
      "d_128.txt: меркель время парижской\n",
      "d_129.txt: государства парижское сша\n",
      "d_130.txt: риски соглашение сша\n",
      "d_131.txt: цукерберг ранее соглашения\n",
      "d_132.txt: температуры соглашение сша\n",
      "d_133.txt: китай сша место\n",
      "d_134.txt: габриэль саммита сша\n",
      "d_135.txt: трамп кампании трамп\n",
      "d_136.txt: будущем страны принимает\n",
      "d_137.txt: сша трамп соглашения\n",
      "d_138.txt: выйдут трамп которая\n",
      "d_139.txt: сообщил трамп сша\n",
      "d_140.txt: государства отметил соглашения\n",
      "d_141.txt: также заявлении парижского\n",
      "d_142.txt: соглашения сша сша\n",
      "d_143.txt: сша соглашение соглашения\n",
      "d_144.txt: трамп сша сша\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_145.txt: борьбы сша парижского\n",
      "d_146.txt: сша соглашение парижского\n",
      "d_147.txt: ходе новых парижского\n",
      "d_148.txt: президента сша заявил\n",
      "d_149.txt: парижского трамп сша\n",
      "d_150.txt: трампа трампа сша\n",
      "d_151.txt: трампу заявил соглашения\n",
      "d_152.txt: парижского сша соглашения\n",
      "d_153.txt: борьбы сша парижского\n",
      "d_154.txt: сша трамп соглашения\n",
      "d_155.txt: соглашение сша сша\n",
      "d_156.txt: сша заявил соглашения\n",
      "d_157.txt: соглашение президент сша\n",
      "d_158.txt: сообщил сша сша\n",
      "d_159.txt: обещания сша соглашения\n",
      "d_160.txt: цукерберг ранее соглашения\n",
      "d_161.txt: цукерберг ранее соглашения\n",
      "d_162.txt: мир хотим сша\n",
      "d_163.txt: соглашение президент сша\n",
      "d_164.txt: сша маск соглашения\n",
      "d_165.txt: других трамп соглашения\n",
      "d_166.txt: трампа климату шульц\n",
      "d_167.txt: хотим климата сша\n",
      "d_168.txt: макрон хотим мир\n",
      "d_169.txt: других очень соглашения\n",
      "d_170.txt: обещания сша соглашения\n",
      "d_171.txt: сша заявлении соглашения\n",
      "d_172.txt: трамп премьер трюдо\n",
      "d_173.txt: спиной меркель соглашения\n",
      "d_174.txt: президент макроном соглашения\n",
      "d_175.txt: мэй трамп соглашения\n",
      "d_176.txt: сша трамп соглашения\n",
      "d_177.txt: клинтон стало отношению\n",
      "d_178.txt: трамп мэй сша\n",
      "d_179.txt: макрон хотим мир\n",
      "d_180.txt: проблем хотим мир\n",
      "d_181.txt: трампа сша трамп\n",
      "d_182.txt: макрон хотим мир\n",
      "d_183.txt: написала дональда президента\n",
      "d_184.txt: сша трамп парижского\n",
      "d_185.txt: оон парникового является\n",
      "d_186.txt: парижская ходе парижского\n",
      "d_187.txt: шварценеггер окружающей неудобная\n",
      "d_188.txt: человек сша шварценеггер\n",
      "d_189.txt: президент трамп соглашения\n",
      "d_190.txt: сша хотим сша\n",
      "d_191.txt: человек моменту актер\n",
      "d_192.txt: словам словам заключенного\n",
      "d_193.txt: соглашения решения климату\n",
      "d_194.txt: планеты решения трампа\n",
      "d_195.txt: трамп американским сша\n",
      "d_196.txt: шварценеггер окружающей неудобная\n",
      "d_197.txt: народом сша суверенитет\n",
      "d_198.txt: керри подчеркнул бывший\n",
      "d_199.txt: миллиардов соглашение трамп\n",
      "d_200.txt: прюитт сша сша\n",
      "d_201.txt: словам прюитт америки\n",
      "d_202.txt: сша парижского сша\n",
      "d_203.txt: большим германии сша\n",
      "d_204.txt: обещания сша соглашения\n",
      "d_205.txt: президент трамп сша\n",
      "d_206.txt: государства обама сша\n",
      "d_207.txt: продавать будущего соглашения\n",
      "d_208.txt: сша году избран\n",
      "d_209.txt: меркель время канцлер\n",
      "d_210.txt: заявлении парижское парижского\n",
      "d_211.txt: трамп либо сша\n",
      "d_212.txt: мэй трамп переговоры\n",
      "d_213.txt: заявлял сша соглашения\n",
      "d_214.txt: выйдет сша сша\n",
      "d_215.txt: мэй трамп меркель\n",
      "d_216.txt: решение сша климату\n",
      "d_217.txt: сша рабочих сша\n",
      "d_218.txt: сша сша соглашения\n",
      "d_219.txt: заявили договоренности стоимости\n",
      "d_220.txt: правительства климата германии\n"
     ]
    }
   ],
   "source": [
    "cluster_list_DNR = Clustering('data_DNR', num_tokens = 1)\n",
    "cluster_list_trump = Clustering('data_trump', num_tokens = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUMP PWS: 0.343488943489\n",
      "DNR PWS: 0.354912632484\n",
      "=========================================\n",
      "TRUMP CPS: 0.384615384615\n",
      "DNR CPS: 0.393939393939\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(class_list_DNR)):\n",
    "    if class_list_DNR[i] == 9:\n",
    "        class_list_DNR[i] = 0\n",
    "print 'TRUMP PWS: ' + str(PWS(class_list = class_list_trump, cluster_list = cluster_list_trump))\n",
    "print 'DNR PWS: ' + str(PWS(class_list = class_list_DNR, cluster_list = cluster_list_DNR))\n",
    "print '========================================='\n",
    "print 'TRUMP CPS: ' + str(CPS(class_list = class_list_trump, cluster_list = cluster_list_trump))\n",
    "print 'DNR CPS: ' + str(CPS(class_list = class_list_DNR, cluster_list = cluster_list_DNR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
